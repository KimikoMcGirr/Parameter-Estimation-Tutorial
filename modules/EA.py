from deap import base, creator, tools, algorithms
import numpy as np
# import model
import os
import h5py

class EA:
    """
    Runs Evolutionary Algorithm to find optimal parameter values
    for our ODE system.

    Parameters
    ----------
    exp_data : Dict
        Dictionary of experimental data
        {int : {'response' : np.array} {'time' : np.array}}

    number_of_params : int
        Number of parameters need to optimize
    number_of_runs : int
        Number of times to run the EA

    Returns
    -------
    runs : np.array
        Array of the top parameters generated by the EA.
    """

    def __init__(self, exp_data, species, sigs, model, minimums, maximums, number_of_runs):
        # Experimental data
        self.exp_response = exp_data['response']
        self.exp_time = exp_data['time']
        # self.exp_time = exp_time

        self.species = species
        self.sigs = sigs
        # Model Parameters
        # self.number_of_params = number_of_params
        self.model = model
        # self.number_of_params = len(self.model.params)
        # self.maximums = maximums
        # self.minimums = minimums

        # EA hyperparameters
        self.number_of_runs = number_of_runs
        self.number_of_generations = 50
        self.number_of_individuals = 20
        self.mutation_rate = 0.1 #optimized
        self.crossover_rate = 0.5 #optimized

        self.minimums = minimums
        self.maximums = maximums

        self.conversion_matrix = self.make_conversion_matrix()

    def run(self, save_sims=''):
        """
        Runs evolutionary algorithm

        Returns
        -------
        top_params : list
            List of the top parameters from an individual EA.
        best_error : list
            List of the best errors from an individual EA run.
        """

        top_params = np.zeros((self.number_of_runs, self.number_of_generations+1, len(self.minimums)))
        best_error = np.zeros((self.number_of_runs, self.number_of_generations+1))

        def scorefxn_helper(ea_individual):
            return self.scorefxn(ea_individual, convert=True),


        for i in range(self.number_of_runs):
            # TYPE
            # Create minimizing fitness class w/ single objective:
            creator.create('FitnessMin', base.Fitness, weights=(-1.0,))
            # Create individual class:
            creator.create('Individual', list, fitness=creator.FitnessMin)

            # TOOLBOX
            toolbox = base.Toolbox()
            # Register function to use initRepeat to fill individual w/ n calls to rand_num:
            toolbox.register('individual', tools.initRepeat, creator.Individual,
                             np.random.random, n=len(self.minimums))
            # Register function to use initRepeat to fill population with individuals:
            toolbox.register('population', tools.initRepeat, list, toolbox.individual)

            # GENETIC OPERATORS:
            # Register evaluate fxn = evaluation function, individual to evaluate given later
            toolbox.register('evaluate', scorefxn_helper)
            # Register mate fxn = two points crossover function
            toolbox.register('mate', tools.cxTwoPoint)
            # Register mutate by swapping two points of the individual:
            toolbox.register('mutate', tools.mutPolynomialBounded,
                             eta=0.1, low=0.0, up=1.0, indpb=0.2)
            # Register select = size of tournament set to 3
            toolbox.register('select', tools.selTournament, tournsize=3)

            # EVOLUTION!
            pop = toolbox.population(n=self.number_of_individuals)
            hof = tools.HallOfFame(1)

            stats = tools.Statistics(key = lambda ind: [ind.fitness.values, ind])
            stats.register('all', np.copy)

            # using built in eaSimple algo
            pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=self.crossover_rate,
                                               mutpb=self.mutation_rate,
                                               ngen=self.number_of_generations,
                                               stats=stats, halloffame=hof,
                                               verbose=False)

            # Save best scores and individuals in population
            best_score = []
            best_ind = []
            for a in range(len(logbook)):
                scores = [logbook[a]['all'][b][0][0] for b in range(len(logbook[a]['all']))]
                best_score.append(np.nanmin(scores))

                # logbook is of type 'deap.creator.Individual' and must be loaded later
                # don't want to have to load it to view data everytime, thus numpy
                ind_np = np.asarray(logbook[a]['all'][np.nanargmin(scores)][1])
                ind_np_conv = self.convert_individual(ind_np)
                best_ind.append(ind_np_conv)

            # print('Best individual is:\n %s\nwith fitness: %s' %(arr_best_ind[-1],arr_best_score[-1]))

            top_params[i] = best_ind
            best_error[i] = best_score

            if i/self.number_of_runs*100 % 10 == 0:
                print(str((i/self.number_of_runs)*100)+'% complete.')

            if save_sims:
                counter = 0
                filename = get_filename(save_sims, counter)
                while os.path.isfile(filename) == True:
                    counter += 1
                    filename = get_filename(save_sims, counter)

                with h5py.File(filename, "w") as f:
                    tparam = f.create_dataset("top_params", data = top_params)
                    berror = f.create_dataset("best_error", data = best_error)
        return top_params, best_error

    def make_conversion_matrix(self):
        # want easily savable matrix to hold this info
        # interp boolean, interp range (min,max), power boolean, power number (y)
        arr_IandP = np.zeros((5,len(self.minimums)))
        # Set all interp booleans to 1 - everything is going to be interpreted
        arr_IandP[0,:] = 1
        # Set all power booleans to 1 - everything is in the form of powers
        arr_IandP[3,:] = 1
        # Set all power numbers to 10 - everything has a base of 10
        arr_IandP[4,:] = 10
        # Set minimums and maximums for all parameters. Parameters are in the following order:

        for i in range(len(self.minimums)):
            arr_IandP[1,i] = self.minimums[i] #interp_range_min
            arr_IandP[2,i] = self.maximums[i] #interp_range_max

        return arr_IandP

    def convert_individual(self, ea_individual):

        arr_params_conv = np.zeros(len(self.minimums))
        len_ind = len(ea_individual)

        # Interp:
        for idx in np.nonzero(self.conversion_matrix[0])[0]:
            ea_val = ea_individual[idx]
            r_min = self.conversion_matrix[1][idx]
            r_max = self.conversion_matrix[2][idx]
            arr_params_conv[idx] = np.interp(ea_val, (0,1), (r_min, r_max))

        # Exponentiate:
        for idx in np.nonzero(self.conversion_matrix[3])[0]:
            ea_val = arr_params_conv[idx]
            base_val = self.conversion_matrix[4][idx]
            arr_params_conv[idx] = np.power(base_val, ea_val)

        return arr_params_conv


    def scorefxn(self, ea_individual, convert=False):
        """
        Simulates and scores how well it fits to experimental data

        Parameters
        ----------
        ea_individual : np.Array
            Array of learned parameters
        convert : bool
            Flag if need to convert from 0>x>1 to log space

        Returns
        -------
        top_params : list
            List of the top parameters from an individual EA.
        best_error : list
            List of the best errors from an individual EA run.
        """
        if convert:
            ea_individual = self.convert_individual(ea_individual)

        # exp_time = self.exp_time
        dt = 0.1
        steps = self.exp_time[-1]*10+1 # last time point
        time = np.linspace(0,dt*steps,steps)

        closest_idxs = [np.abs(time - t).argmin() for t in self.exp_time]

        # run model to steady state
        ss_inits = self.model.run_ss(ea_individual)

        def fit_to_data(odes, species, response):
            fitted_species = odes[:,species]
            error = np.absolute(response - fitted_species[closest_idxs]).mean() #SSE
            return error

        #simulation + fitting to data
        mse_total = 0
        for sig in self.sigs:
            odes = self.model.run_simulation(ea_individual, sig)
            for s, resp in zip(self.species, self.exp_response):
                mse_total += fit_to_data(odes, s, resp[s])
        return mse_total

def sort_sims(top_params, best_error, gen=-1):
    best_error = np.array([top_params[i][gen] for i in range(len(top_params))])
    top_params = np.array([best_error[i][gen] for i in range(len(best_error))])
    return best_error[np.argsort(best_error)], top_params[np.argsort(best_error)]

def get_filename(d, val):

    if val < 10:
        toret = '000' + str(val)
    elif 10 <= val < 100:
        toret = '00' + str(val)
    elif 100 <= val < 1000:
        toret = '0' + str(val)
    else:
        toret = str(val)
    return d + toret + ".hdf5"
